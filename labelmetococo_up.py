#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì¢… ìˆ˜ì •ëœ Labelme to COCO ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
íŒŒì¼ëª… ì •ê·œí™” ë¬¸ì œ ì™„ì „ í•´ê²°
"""

import json
import os
import re
import shutil
import random
import hashlib
from pathlib import Path
from PIL import Image
import numpy as np

def safe_normalize_filename(filename):
    """
    íŒŒì¼ëª…ì„ ì™„ì „íˆ ì•ˆì „í•œ ASCII ë¬¸ìë¡œ ì •ê·œí™”
    """
    # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬
    name_part = Path(filename).stem
    ext_part = Path(filename).suffix.lower()
    
    # 1ë‹¨ê³„: ëª¨ë“  ë¹„ASCII ë¬¸ìë¥¼ ì œê±°í•˜ê³  ì•ˆì „í•œ ë¬¸ìë§Œ ìœ ì§€
    # í•œê¸€, ì¤‘êµ­ì–´, ì¼ë³¸ì–´, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ëª¨ë‘ ì œê±°
    safe_chars = re.sub(r'[^a-zA-Z0-9_\-]', '_', name_part)
    
    # 2ë‹¨ê³„: ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
    safe_chars = re.sub(r'_+', '_', safe_chars)
    
    # 3ë‹¨ê³„: ì•ë’¤ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
    safe_chars = safe_chars.strip('_')
    
    # 4ë‹¨ê³„: ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° í•´ì‹œ ê¸°ë°˜ ì´ë¦„ ìƒì„±
    if len(safe_chars) < 3:
        # ì›ë³¸ íŒŒì¼ëª…ì˜ í•´ì‹œê°’ ì‚¬ìš©
        hash_obj = hashlib.md5(filename.encode('utf-8'))
        safe_chars = f"img_{hash_obj.hexdigest()[:12]}"
    
    # 5ë‹¨ê³„: ë„ˆë¬´ ê¸´ ì´ë¦„ ì¤„ì´ê¸° (ìµœëŒ€ 50ì)
    if len(safe_chars) > 50:
        safe_chars = safe_chars[:50]
    
    # 6ë‹¨ê³„: í™•ì¥ì ì •ê·œí™”
    if not ext_part:
        ext_part = '.jpg'
    elif ext_part not in ['.jpg', '.jpeg', '.png', '.bmp']:
        ext_part = '.jpg'
    
    return f"{safe_chars}{ext_part}"

def polygon_to_bbox(points):
    """í´ë¦¬ê³¤ì„ ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ë³€í™˜"""
    if not points or len(points) < 3:
        return None
    
    x_coords = [p[0] for p in points]
    y_coords = [p[1] for p in points]
    
    x_min, x_max = min(x_coords), max(x_coords)
    y_min, y_max = min(y_coords), max(y_coords)
    
    width = x_max - x_min
    height = y_max - y_min
    
    if width <= 0 or height <= 0:
        return None
    
    return [x_min, y_min, width, height]

def convert_labelme_to_coco_final(
    labelme_folder, 
    export_dir, 
    train_split_rate=0.8
):
    """
    ì™„ì „íˆ ìˆ˜ì •ëœ Labelme to COCO ë³€í™˜
    """
    print(f"ğŸ”„ ìµœì¢… Labelme â†’ COCO ë³€í™˜ ì‹œì‘")
    
    labelme_path = Path(labelme_folder)
    export_path = Path(export_dir)
    
    # ê¸°ì¡´ ì¶œë ¥ í´ë” ì™„ì „ ì‚­ì œ
    if export_path.exists():
        shutil.rmtree(export_path)
    export_path.mkdir(exist_ok=True)
    
    # Labelme JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(labelme_path.glob("*.json"))
    if not json_files:
        raise FileNotFoundError(f"Labelme JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labelme_path}")
    
    print(f"ğŸ“ ë°œê²¬ëœ Labelme íŒŒì¼: {len(json_files)}ê°œ")
    
    # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì¹´ìš´í„°
    used_names = set()
    name_counter = {}
    
    # ë°ì´í„° ìˆ˜ì§‘ ë° íŒŒì¼ ë³µì‚¬
    all_data = []
    categories = set()
    
    print("ğŸ“‹ ë°ì´í„° ìˆ˜ì§‘ ë° íŒŒì¼ëª… ì •ê·œí™” ì¤‘...")
    
    for i, json_file in enumerate(json_files):
        if i % 500 == 0:
            print(f"  ì§„í–‰: {i}/{len(json_files)}")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                labelme_data = json.load(f)
            
            image_path = labelme_data.get('imagePath', '')
            if not image_path:
                continue
            
            # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            original_image_path = labelme_path / image_path
            if not original_image_path.exists():
                continue
            
            # íŒŒì¼ëª… ì •ê·œí™” (ì¤‘ë³µ ë°©ì§€)
            base_normalized = safe_normalize_filename(image_path)
            normalized_name = base_normalized
            
            # ì¤‘ë³µëœ ì´ë¦„ì¸ ê²½ìš° ë²ˆí˜¸ ì¶”ê°€
            if normalized_name in used_names:
                if base_normalized not in name_counter:
                    name_counter[base_normalized] = 1
                else:
                    name_counter[base_normalized] += 1
                
                name_part = Path(base_normalized).stem
                ext_part = Path(base_normalized).suffix
                normalized_name = f"{name_part}_{name_counter[base_normalized]:03d}{ext_part}"
            
            used_names.add(normalized_name)
            
            # ì´ë¯¸ì§€ ì •ë³´
            image_width = labelme_data.get('imageWidth', 0)
            image_height = labelme_data.get('imageHeight', 0)
            
            # ì‹¤ì œ ì´ë¯¸ì§€ì—ì„œ í¬ê¸° í™•ì¸
            if image_width == 0 or image_height == 0:
                try:
                    with Image.open(original_image_path) as img:
                        image_width, image_height = img.size
                except:
                    continue
            
            # ì–´ë…¸í…Œì´ì…˜ ì²˜ë¦¬
            annotations = []
            for shape in labelme_data.get('shapes', []):
                if shape['shape_type'] not in ['polygon', 'rectangle']:
                    continue
                
                label = shape.get('label', '')
                if not label:
                    continue
                
                categories.add(label)
                points = shape.get('points', [])
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜
                if shape['shape_type'] == 'rectangle' and len(points) == 2:
                    x1, y1 = points[0]
                    x2, y2 = points[1]
                    bbox = [min(x1, x2), min(y1, y2), abs(x2-x1), abs(y2-y1)]
                else:
                    bbox = polygon_to_bbox(points)
                
                if bbox and bbox[2] > 0 and bbox[3] > 0:
                    annotations.append({
                        'label': label,
                        'bbox': bbox,
                        'area': bbox[2] * bbox[3]
                    })
            
            if annotations:
                all_data.append({
                    'original_path': str(original_image_path),
                    'normalized_name': normalized_name,
                    'width': image_width,
                    'height': image_height,
                    'annotations': annotations
                })
        
        except Exception as e:
            print(f"  âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {json_file} - {e}")
            continue
    
    if not all_data:
        raise ValueError("ë³€í™˜í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"âœ… ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(all_data)}ê°œ")
    print(f"ğŸ“‹ ë°œê²¬ëœ ì¹´í…Œê³ ë¦¬: {sorted(categories)}")
    
    # ì¹´í…Œê³ ë¦¬ ì •ë³´ ìƒì„± (ID 0ë¶€í„° ì‹œì‘)
    category_list = []
    for idx, cat_name in enumerate(sorted(categories), 0):
        category_list.append({
            'id': idx,
            'name': cat_name,
            'supercategory': cat_name
        })
    
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    random.shuffle(all_data)
    split_idx = int(len(all_data) * train_split_rate)
    train_data = all_data[:split_idx]
    val_data = all_data[split_idx:]
    
    print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ")
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(val_data)}ê°œ")
    
    # í´ë” ìƒì„± ë° ì´ë¯¸ì§€ ë³µì‚¬
    train_dir = export_path / "train"
    valid_dir = export_path / "valid"
    train_dir.mkdir(exist_ok=True)
    valid_dir.mkdir(exist_ok=True)
    
    # COCO í˜•ì‹ ë³€í™˜ ë° ì´ë¯¸ì§€ ë³µì‚¬
    for split_name, split_data, split_dir in [
        ('train', train_data, train_dir), 
        ('valid', val_data, valid_dir)
    ]:
        print(f"\nğŸ“ {split_name} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # COCO í˜•ì‹ ë³€í™˜ ë° ì´ë¯¸ì§€ ë³µì‚¬
        coco_data = {
            'info': {
                'year': 2025,
                'version': '1.0',
                'description': 'Custom dataset converted from Labelme',
                'contributor': 'RF-DETR Training',
                'url': '',
                'date_created': '2025-01-01'
            },
            'licenses': [
                {
                    'id': 1,
                    'name': 'Custom License',
                    'url': ''
                }
            ],
            'images': [],
            'annotations': [],
            'categories': category_list
        }
        
        annotation_id = 1
        copied_count = 0
        
        for img_idx, data_item in enumerate(split_data, 1):
            # ì´ë¯¸ì§€ ë³µì‚¬
            src_path = Path(data_item['original_path'])
            dst_path = split_dir / data_item['normalized_name']
            
            try:
                shutil.copy(str(src_path), str(dst_path))
                copied_count += 1
            except Exception as e:
                print(f"    âŒ ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨: {src_path} -> {dst_path} ({e})")
                continue
            
            # ì´ë¯¸ì§€ ì •ë³´
            image_info = {
                'id': img_idx,
                'file_name': data_item['normalized_name'],
                'width': data_item['width'],
                'height': data_item['height']
            }
            coco_data['images'].append(image_info)
            
            # ì–´ë…¸í…Œì´ì…˜ ì •ë³´
            for ann in data_item['annotations']:
                category_id = next(cat['id'] for cat in category_list if cat['name'] == ann['label'])
                
                annotation_info = {
                    'id': annotation_id,
                    'image_id': img_idx,
                    'category_id': category_id,
                    'bbox': ann['bbox'],
                    'area': ann['area'],
                    'iscrowd': 0
                }
                
                coco_data['annotations'].append(annotation_info)
                annotation_id += 1
        
        # JSON íŒŒì¼ ì €ì¥
        json_output = split_dir / "_annotations.coco.json"
        with open(json_output, 'w', encoding='utf-8') as f:
            json.dump(coco_data, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ… {copied_count}ê°œ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ")
        print(f"  âœ… {len(coco_data['annotations'])}ê°œ ì–´ë…¸í…Œì´ì…˜ ìƒì„±")
        print(f"  âœ… {json_output} ì €ì¥ ì™„ë£Œ")
    
    return export_dir

def create_test_split_final(coco_dir, test_ratio=0.5):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  ë° JSON ë™ê¸°í™”"""
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (ë¹„ìœ¨: {test_ratio})...")
    coco_path = Path(coco_dir)
    valid_dir = coco_path / "valid"
    test_dir = coco_path / "test"
    test_dir.mkdir(exist_ok=True)

    # valid JSON ë¡œë“œ
    valid_json = valid_dir / "_annotations.coco.json"
    if not valid_json.exists():
        print("  âš ï¸ valid JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(valid_json, 'r', encoding='utf-8') as f:
        valid_data = json.load(f)

    # valid í´ë”ì˜ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
    valid_image_files = list(valid_dir.glob("*.jpg")) + list(valid_dir.glob("*.png"))
    valid_filenames = {img.name for img in valid_image_files}
    
    print(f"  ğŸ“ valid í´ë” ì‹¤ì œ ì´ë¯¸ì§€: {len(valid_image_files)}ê°œ")
    print(f"  ğŸ“„ valid JSON ì´ë¯¸ì§€ ì •ë³´: {len(valid_data['images'])}ê°œ")

    # JSONì—ì„œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ë§Œ í•„í„°ë§
    existing_images = [img for img in valid_data['images'] if img['file_name'] in valid_filenames]
    existing_image_ids = {img['id'] for img in existing_images}
    existing_annotations = [ann for ann in valid_data['annotations'] if ann['image_id'] in existing_image_ids]
    
    print(f"  ğŸ” ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€: {len(existing_images)}ê°œ")

    if not existing_images:
        print("  âš ï¸ valid í´ë”ì— ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ì„ íƒ
    num_test = int(len(existing_images) * test_ratio)
    if num_test == 0 and len(existing_images) > 0:
        num_test = 1
    
    # ëœë¤í•˜ê²Œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ íƒ
    test_images_info = random.sample(existing_images, num_test)
    test_filenames = {img['file_name'] for img in test_images_info}
    test_image_ids = {img['id'] for img in test_images_info}
    
    # ë‚¨ì€ valid ì´ë¯¸ì§€ ì •ë³´
    remaining_valid_images = [img for img in existing_images if img['file_name'] not in test_filenames]
    remaining_valid_ids = {img['id'] for img in remaining_valid_images}
    
    print(f"  ğŸ“Š í…ŒìŠ¤íŠ¸ë¡œ ì´ë™: {len(test_images_info)}ê°œ")
    print(f"  ğŸ“Š validì— ë‚¨ìŒ: {len(remaining_valid_images)}ê°œ")

    # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì´ë™
    moved_count = 0
    for filename in test_filenames:
        src_path = valid_dir / filename
        dst_path = test_dir / filename
        if src_path.exists():
            shutil.move(str(src_path), str(dst_path))
            moved_count += 1
    
    print(f"  âœ… {moved_count}ê°œ ì´ë¯¸ì§€ íŒŒì¼ì„ test í´ë”ë¡œ ì´ë™")

    # ì–´ë…¸í…Œì´ì…˜ ë¶„í• 
    test_annotations = [ann for ann in existing_annotations if ann['image_id'] in test_image_ids]
    remaining_valid_annotations = [ann for ann in existing_annotations if ann['image_id'] in remaining_valid_ids]

    # test JSON ìƒì„±
    test_data = {
        "info": {
            "year": 2025,
            "version": "1.0",
            "description": "Test split of custom dataset",
            "contributor": "RF-DETR Training",
            "url": "",
            "date_created": "2025-01-01"
        },
        "licenses": [
            {
                "id": 1,
                "name": "Custom License",
                "url": ""
            }
        ],
        "images": test_images_info,
        "annotations": test_annotations,
        "categories": valid_data['categories']
    }

    test_json = test_dir / "_annotations.coco.json"
    with open(test_json, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… test JSON ìƒì„±: {len(test_images_info)}ê°œ ì´ë¯¸ì§€, {len(test_annotations)}ê°œ ì–´ë…¸í…Œì´ì…˜")

    # valid JSON ì—…ë°ì´íŠ¸ (ë‚¨ì€ ë°ì´í„°ë§Œ)
    updated_valid_data = {
        "info": valid_data.get('info', {
            "year": 2025,
            "version": "1.0", 
            "description": "Valid split of custom dataset",
            "contributor": "RF-DETR Training",
            "url": "",
            "date_created": "2025-01-01"
        }),
        "licenses": valid_data.get('licenses', [
            {
                "id": 1,
                "name": "Custom License", 
                "url": ""
            }
        ]),
        "images": remaining_valid_images,
        "annotations": remaining_valid_annotations,
        "categories": valid_data['categories']
    }

    with open(valid_json, 'w', encoding='utf-8') as f:
        json.dump(updated_valid_data, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… valid JSON ì—…ë°ì´íŠ¸: {len(remaining_valid_images)}ê°œ ì´ë¯¸ì§€, {len(remaining_valid_annotations)}ê°œ ì–´ë…¸í…Œì´ì…˜")

def final_verification(coco_dir):
    """ìµœì¢… ê²€ì¦"""
    print(f"\nğŸ” ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦...")
    coco_path = Path(coco_dir)
    
    all_good = True
    
    for split in ["train", "valid", "test"]:
        split_dir = coco_path / split
        json_file = split_dir / "_annotations.coco.json"
        
        if not split_dir.exists():
            if split == "test":
                print(f"  - {split}: ì„ íƒì‚¬í•­ (ì—†ìŒ)")
                continue
            else:
                print(f"  âŒ {split}: í´ë” ì—†ìŒ")
                all_good = False
                continue
        
        if not json_file.exists():
            print(f"  âŒ {split}: JSON íŒŒì¼ ì—†ìŒ")
            all_good = False
            continue
        
        # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜
        image_files = list(split_dir.glob("*.jpg")) + list(split_dir.glob("*.png"))
        
        # JSON ì •ë³´ í™•ì¸
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        json_images = len(data.get('images', []))
        json_annotations = len(data.get('annotations', []))
        
        print(f"  âœ… {split}:")
        print(f"     ğŸ“ ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
        print(f"     ğŸ“„ JSON ì´ë¯¸ì§€: {json_images}ê°œ")
        print(f"     ğŸ·ï¸ ì–´ë…¸í…Œì´ì…˜: {json_annotations}ê°œ")
        
        if len(image_files) != json_images:
            print(f"     âŒ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì™€ JSON ì •ë³´ ë¶ˆì¼ì¹˜!")
            all_good = False
        
        # íŒŒì¼ëª… ê²€ì¦ (ASCIIë§Œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        non_ascii_files = []
        for img_file in image_files:
            try:
                img_file.name.encode('ascii')
            except UnicodeEncodeError:
                non_ascii_files.append(img_file.name)
        
        if non_ascii_files:
            print(f"     âŒ ë¹„ASCII íŒŒì¼ëª… ë°œê²¬: {len(non_ascii_files)}ê°œ")
            all_good = False
        else:
            print(f"     âœ… ëª¨ë“  íŒŒì¼ëª…ì´ ASCIIë¡œ ì •ê·œí™”ë¨")
    
    if all_good:
        print(f"\nğŸ‰ ë°ì´í„°ì…‹ì´ ì™„ë²½í•˜ê²Œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ì´ì œ ì•ˆì „í•˜ê²Œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâŒ ì¼ë¶€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
    
    return all_good

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ”§ íŒŒì¼ëª… ì •ê·œí™” ë¬¸ì œ ì™„ì „ í•´ê²° ë²„ì „")
    print("   - ëª¨ë“  í•œê¸€/íŠ¹ìˆ˜ë¬¸ì â†’ ASCII ë³€í™˜")
    print("   - íŒŒì¼ ë³µì‚¬ì™€ JSON ì •ë³´ ì™„ì „ ë™ê¸°í™”")
    print("   - RF-DETR 100% í˜¸í™˜")
    print("=" * 70)
    
    # === ì„¤ì • ===
    labelme_folder = "testdataset"
    export_dir = "cocoeddata"
    train_split_rate = 0.8
    test_split_rate = 0.5
    # === ì„¤ì • ë ===
    
    if not Path(labelme_folder).exists():
        print(f"âŒ ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {labelme_folder}")
        return False

    try:
        # 1ë‹¨ê³„: ì™„ì „í•œ ë³€í™˜
        print(f"\n{'='*20} 1ë‹¨ê³„: ì™„ì „í•œ Labelme â†’ COCO ë³€í™˜ {'='*20}")
        convert_labelme_to_coco_final(labelme_folder, export_dir, train_split_rate)
        
        # 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë¶„í• 
        print(f"\n{'='*20} 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  {'='*20}")
        create_test_split_final(export_dir, test_split_rate)
        
        # 3ë‹¨ê³„: ìµœì¢… ê²€ì¦
        print(f"\n{'='*20} 3ë‹¨ê³„: ìµœì¢… ê²€ì¦ {'='*20}")
        success = final_verification(export_dir)
        
        if success:
            print(f"\nğŸ‰ ëª¨ë“  ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ì´ì œ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”:")
            print(f"python3 customtrain.py")
        
        return success
        
    except Exception as e:
        print(f"\nâŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
